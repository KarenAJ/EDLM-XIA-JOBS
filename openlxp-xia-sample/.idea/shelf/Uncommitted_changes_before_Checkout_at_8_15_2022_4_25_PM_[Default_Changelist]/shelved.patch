Index: requirements.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>beautifulsoup4~=4.11.1\n\nboto3~=1.20.24\n\nbotocore~=1.23.45\n\ncelery>=5.2.0, <5.2.3\n\ncoverage>=5.5,<6.0\n\nddt~=1.4.2 , <1.5.0\n\nDjango>=3.2.3,<4.0.0\n\ndjango-celery-beat >=2.2.1, <2.3.0\n\ndjango-celery-results >=2.2.0, <2.3.0\n\ndjango-model-utils>=4.1.1,<4.2.0\n\ndjango-mysql>=4.4.0,<4.5.0\n\ndjangorestframework>=3.13.0,<3.13.1\n\ndjango-ses>=2.2.0 , <2.3.1\n\nflake8>=3.9.0,<4.0.1\n\nflower <=1.0.0\n\nfsspec>=2022.1.0\n\ngunicorn>=20.1.0,<20.2.0\n\nhtml2text~=2020.1.16\n\nmartor>=1.6.0,<1.6.10\n\nmysql-connector-python>= 8.0.28\n\nnumpy>=1.21.1\n\nopenlxp-notification >=1.3.2, <1.3.3\n\nopenlxp-xia >=1.3.0\n\nopenpyxl >=3.0.7 , <3.1.0\n\npandas>=1.3.5,<1.4.0\n\nPillow >=9.0.0\n\npytz >=2021.1, <2021.3\n\nredis==4.1.2\n\nrequests~=2.27.1\n\ns3fs==0.4.2\n\nxlrd >=2.0.1 , <2.1.0\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/requirements.txt b/requirements.txt
--- a/requirements.txt	(revision 3e49fc5ff3ec8d34e601683144ddb91997a5838c)
+++ b/requirements.txt	(date 1658949483638)
@@ -36,7 +36,7 @@
 
 martor>=1.6.0,<1.6.10
 
-mysql-connector-python>= 8.0.28
+mysql-connector-python== 8.0.29
 
 numpy>=1.21.1
 
Index: app/core/management/utils/xsr_client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from datetime import datetime\nimport hashlib\nimport json\nimport logging\nimport html2text\n\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport requests\nfrom openlxp_xia.management.utils.xia_internal import get_key_dict, \\\n    dict_flatten, traverse_dict_with_key_list\n\nfrom core.models import XSRConfiguration\n\nlogger = logging.getLogger('dict_config_logger')\n\n\ndef get_xsr_api_endpoint():\n    \"\"\"Setting API endpoint from XIA and XIS communication \"\"\"\n    logger.debug(\"Retrieve xsr_api_endpoint from XSR configuration\")\n    xsr_data = XSRConfiguration.objects.first()\n    xsr_api_endpoint = xsr_data.xsr_api_endpoint\n    return xsr_api_endpoint\n\n\ndef get_xsr_api_response():\n    \"\"\"Function to get api response from xsr endpoint\"\"\"\n    # url of rss feed\n    url = get_xsr_api_endpoint()\n\n    # creating HTTP response object from given url\n    try:\n        resp = requests.get(url)\n    except requests.exceptions.RequestException as e:\n        logger.error(e)\n        raise SystemExit('Exiting! Can not make connection with XSR.')\n\n    return resp\n\n\ndef extract_source():\n    \"\"\"function to parse xml xsr data and convert to dictionary\"\"\"\n\n    resp = get_xsr_api_response()\n    source_data_dict = json.loads(resp.text)\n\n    logger.info(\"Retrieving data from source page \")\n    source_df_list = [pd.DataFrame(source_data_dict)]\n    source_df_final = pd.concat(source_df_list).reset_index(drop=True)\n    logger.info(\"Completed retrieving data from source\")\n    return source_df_final\n\n\ndef read_source_file():\n    \"\"\"sending source data in dataframe format\"\"\"\n    logger.info(\"Retrieving data from XSR\")\n    # load rss from web to convert to xml\n    xsr_items = extract_source()\n    # convert xsr dictionary list to Dataframe\n    source_df = pd.DataFrame(xsr_items)\n    logger.info(\"Changing null values to None for source dataframe\")\n    std_source_df = source_df.where(pd.notnull(source_df),\n                                    None)\n    return [std_source_df]\n\n\ndef get_source_metadata_key_value(data_dict):\n    \"\"\"Function to create key value for source metadata \"\"\"\n    # field names depend on source data and SOURCESYSTEM is system generated\n    field = ['shortname', 'SOURCESYSTEM']\n    field_values = []\n\n    for item in field:\n        if not data_dict.get(item):\n            logger.error('Field name ' + item + ' is missing for '\n                                                'key creation')\n            return None\n        field_values.append(data_dict.get(item))\n\n    # Key value creation for source metadata\n    key_value = '_'.join(field_values)\n\n    # Key value hash creation for source metadata\n    key_value_hash = hashlib.sha512(key_value.encode('utf-8')).hexdigest()\n\n    # Key dictionary creation for source metadata\n    key = get_key_dict(key_value, key_value_hash)\n\n    return key\n\n\ndef convert_int_to_date(element, target_data_dict):\n    \"\"\"Convert integer date to date time\"\"\"\n    key_list = element.split(\".\")\n    check_key_dict = target_data_dict\n    check_key_dict = traverse_dict_with_key_list(check_key_dict, key_list)\n    if check_key_dict:\n        if key_list[-1] in check_key_dict:\n            if isinstance(check_key_dict[key_list[-1]], int):\n                check_key_dict[key_list[-1]] = datetime. \\\n                    fromtimestamp(check_key_dict[key_list[-1]])\n\n\ndef find_dates(data_dict):\n    \"\"\"Function to convert integer value to date value \"\"\"\n\n    data_flattened = dict_flatten(data_dict, [])\n\n    for element in data_flattened.keys():\n        element_lower = element.lower()\n        if (element_lower.find(\"date\") != -1 or element_lower.find(\n                \"time\")) != -1:\n            convert_int_to_date(element, data_dict)\n    return data_dict\n\n\ndef convert_html(element, target_data_dict):\n    \"\"\"Convert HTML to text data\"\"\"\n    key_list = element.split(\".\")\n    check_key_dict = target_data_dict\n    check_key_dict = traverse_dict_with_key_list(check_key_dict, key_list)\n    if check_key_dict:\n        if key_list[-1] in check_key_dict:\n            check_key_dict[key_list[-1]] = \\\n                html2text.html2text(check_key_dict[key_list[-1]])\n\n\ndef find_html(data_dict):\n    \"\"\"Function to convert HTML value to text\"\"\"\n    data_flattened = dict_flatten(data_dict, [])\n\n    for element in data_flattened.keys():\n        if data_flattened[element]:\n            if bool(BeautifulSoup(str(data_flattened[element]),\n                                  \"html.parser\").find()):\n                convert_html(element, data_dict)\n    return data_dict\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/core/management/utils/xsr_client.py b/app/core/management/utils/xsr_client.py
--- a/app/core/management/utils/xsr_client.py	(revision 3e49fc5ff3ec8d34e601683144ddb91997a5838c)
+++ b/app/core/management/utils/xsr_client.py	(date 1660591907823)
@@ -135,3 +135,13 @@
                                   "html.parser").find()):
                 convert_html(element, data_dict)
     return data_dict
+
+
+def add_url_to_course(temp_val):
+    """function to add url to course"""
+    base_url = get_xsr_api_endpoint()
+    base_url = base_url.split("webservice")[0]
+    if temp_val["id"]:
+        url = base_url + "course/view.php?id=" + str(temp_val["id"])
+        temp_val["url"] = url
+    return temp_val
Index: app/core/management/commands/extract_source_metadata.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import hashlib\nimport json\nimport logging\nimport numpy as np\nimport pandas as pd\nfrom django.core.management.base import BaseCommand\nfrom django.utils import timezone\nfrom openlxp_xia.management.utils.xia_internal import (\n    convert_date_to_isoformat, get_publisher_detail)\nfrom openlxp_xia.models import MetadataLedger\n\nfrom core.management.utils.xsr_client import (get_source_metadata_key_value,\n                                              read_source_file, find_dates,\n                                              find_html)\n\nlogger = logging.getLogger('dict_config_logger')\n\n\ndef get_source_metadata():\n    \"\"\"Retrieving source metadata\"\"\"\n\n    #  Retrieve metadata from agents as a list of sources\n    df_source_list = read_source_file()\n\n    # Iterate through the list of sources and extract metadata\n    for source_item in df_source_list:\n        logger.info('Loading metadata to be extracted from source')\n\n        # Changing null values to None for source dataframe\n        std_source_df = source_item.where(pd.notnull(source_item),\n                                          None)\n        if std_source_df.empty:\n            logger.error(\"Source metadata is empty!\")\n        extract_metadata_using_key(std_source_df)\n\n\ndef add_publisher_to_source(source_df):\n    \"\"\"Add publisher column to source metadata and return source metadata\"\"\"\n\n    # Get publisher name from system operator\n    publisher = get_publisher_detail()\n    if not publisher:\n        logger.warning(\"Publisher field is empty!\")\n    # Assign publisher column to source data\n    source_df['SOURCESYSTEM'] = publisher\n    return source_df\n\n\ndef store_source_metadata(key_value, key_value_hash, hash_value, metadata):\n    \"\"\"Extract data from Experience Source Repository(XSR)\n        and store in metadata ledger\n    \"\"\"\n    # Setting record_status & deleted_date for updated record\n    MetadataLedger.objects.filter(\n        source_metadata_key_hash=key_value_hash,\n        record_lifecycle_status='Active').exclude(\n        source_metadata_hash=hash_value).update(\n        metadata_record_inactivation_date=timezone.now())\n    MetadataLedger.objects.filter(\n        source_metadata_key_hash=key_value_hash,\n        record_lifecycle_status='Active').exclude(\n        source_metadata_hash=hash_value).update(\n        record_lifecycle_status='Inactive')\n\n    # Retrieving existing records or creating new record to MetadataLedger\n    MetadataLedger.objects.get_or_create(\n        source_metadata_key=key_value,\n        source_metadata_key_hash=key_value_hash,\n        source_metadata=metadata,\n        source_metadata_hash=hash_value,\n        record_lifecycle_status='Active')\n\n\ndef extract_metadata_using_key(source_df):\n    \"\"\"Creating key, hash of key & hash of metadata \"\"\"\n    # Convert source data to dictionary and add publisher to metadata\n    source_df = add_publisher_to_source(source_df)\n    source_remove_nan_df = source_df.replace(np.nan, '', regex=True)\n    source_data_dict = source_remove_nan_df.to_dict(orient='index')\n\n    logger.info('Setting record_status & deleted_date for updated record')\n    logger.info('Getting existing records or creating new record to '\n                'MetadataLedger')\n    for temp_key, temp_val in source_data_dict.items():\n\n        # key dictionary creation function called\n        key = \\\n            get_source_metadata_key_value(source_data_dict[temp_key])\n        # function to convert int to date\n        temp_val_date_convert = find_dates(temp_val)\n        # function to convert HTML to text\n        temp_val_html_convert = find_html(temp_val_date_convert)\n        # function to convert date to iso format\n        temp_val_convert = json.dumps(temp_val_html_convert,\n                                      default=convert_date_to_isoformat)\n        temp_val_json = json.loads(temp_val_convert)\n        # creating hash value of metadata\n        hash_value = hashlib.sha512(str(temp_val_json).encode('utf-8')). \\\n            hexdigest()\n        if key:\n            # Call store function with key, hash of key, hash of metadata,\n            # metadata\n            store_source_metadata(key['key_value'], key['key_value_hash'],\n                                  hash_value, temp_val_json)\n\n\nclass Command(BaseCommand):\n    \"\"\"Django command to extract data from Experience Source Repository (\n    XSR) \"\"\"\n\n    def handle(self, *args, **options):\n        \"\"\"\n            Metadata is extracted from XSR and stored in Metadata Ledger\n        \"\"\"\n        get_source_metadata()\n\n        logger.info('MetadataLedger updated with extracted data from XSR')\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/app/core/management/commands/extract_source_metadata.py b/app/core/management/commands/extract_source_metadata.py
--- a/app/core/management/commands/extract_source_metadata.py	(revision 3e49fc5ff3ec8d34e601683144ddb91997a5838c)
+++ b/app/core/management/commands/extract_source_metadata.py	(date 1660591191637)
@@ -11,7 +11,7 @@
 
 from core.management.utils.xsr_client import (get_source_metadata_key_value,
                                               read_source_file, find_dates,
-                                              find_html)
+                                              find_html, add_url_to_course)
 
 logger = logging.getLogger('dict_config_logger')
 
@@ -86,8 +86,11 @@
         # key dictionary creation function called
         key = \
             get_source_metadata_key_value(source_data_dict[temp_key])
+
+        # function to add url to course
+        temp_val_with_url = add_url_to_course(temp_val)
         # function to convert int to date
-        temp_val_date_convert = find_dates(temp_val)
+        temp_val_date_convert = find_dates(temp_val_with_url)
         # function to convert HTML to text
         temp_val_html_convert = find_html(temp_val_date_convert)
         # function to convert date to iso format
Index: docker-compose.yml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>version: \"3\"\n\nservices:\n  db_xia_moodle:\n    image: mysql:5.7\n    ports:\n      - '3306:3306'\n    environment:\n      MYSQL_DATABASE: \"${DB_NAME}\"\n      MYSQL_PASSWORD: \"${DB_PASSWORD}\"\n      MYSQL_ROOT_PASSWORD: \"${DB_ROOT_PASSWORD}\"\n      MYSQL_HOST: ''\n    networks:\n      - openlxp\n\n  app_xia_moodle:\n    build:\n      context: .\n    ports:\n      - \"8000:8020\"\n    command: >\n      sh -c \". /opt/app/start-app.sh\"\n    environment:\n      DB_NAME: \"${DB_NAME}\"\n      DB_USER: \"${DB_USER}\"\n      DB_PASSWORD: \"${DB_PASSWORD}\"\n      DB_HOST: \"${DB_HOST}\"\n      DJANGO_SUPERUSER_USERNAME: \"${DJANGO_SUPERUSER_USERNAME}\"\n      DJANGO_SUPERUSER_PASSWORD: \"${DJANGO_SUPERUSER_PASSWORD}\"\n      DJANGO_SUPERUSER_EMAIL: \"${DJANGO_SUPERUSER_EMAIL}\"\n      BUCKET_NAME: \"${BUCKET_NAME}\"\n      AWS_ACCESS_KEY_ID: \"${AWS_ACCESS_KEY_ID}\"\n      AWS_SECRET_ACCESS_KEY: \"${AWS_SECRET_ACCESS_KEY}\"\n      AWS_DEFAULT_REGION: \"${AWS_DEFAULT_REGION}\"\n      REQUESTS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'\n      AWS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'\n      SECRET_KEY_VAL: \"${SECRET_KEY_VAL}\"\n    volumes:\n      - ./app:/opt/app/openlxp-xia-moodle\n    depends_on:\n      - db_xia_moodle\n    networks:\n      - openlxp\n\n  redis:\n    image: redis:alpine\n    networks:\n      - openlxp\n\n  celery:\n    build:\n      context: .\n    command: celery -A openlxp_xia_moodle_project worker -l info --pool=solo\n    volumes:\n      - ./app:/opt/app/openlxp-xia-moodle\n    environment:\n      REQUESTS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'\n      AWS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'\n    env_file:\n      - ./.env\n    depends_on:\n      - db_xia_moodle\n      - redis\n      - app_xia_moodle\n    networks:\n      - openlxp\n    restart: on-failure\n\n  celery-beat:\n    build:\n      context: .\n    command: celery -A openlxp_xia_moodle_project beat --scheduler django_celery_beat.schedulers:DatabaseScheduler --loglevel=info --pidfile=/tmp/celerybeat.pid\n    volumes:\n      - ./app:/opt/app/openlxp-xia-moodle\n    environment:\n      REQUESTS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'\n      AWS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'\n    env_file:\n      - ./.env\n    depends_on:\n      - db_xia_moodle\n      - redis\n      - app_xia_moodle\n    networks:\n      - openlxp\n    restart: on-failure\n\n#  flower:\n#    image: mher/flower:0.9.7\n#    command: [ \"flower\", \"--broker=redis://redis:6379/0\", \"--port=8888\" ]\n#    ports:\n#      - 8888:8888\n#    networks:\n#      - openlxp\n\nnetworks:\n  openlxp:\n    external: true\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/docker-compose.yml b/docker-compose.yml
--- a/docker-compose.yml	(revision 3e49fc5ff3ec8d34e601683144ddb91997a5838c)
+++ b/docker-compose.yml	(date 1658520056954)
@@ -37,6 +37,7 @@
       SECRET_KEY_VAL: "${SECRET_KEY_VAL}"
     volumes:
       - ./app:/opt/app/openlxp-xia-moodle
+      - C:/Users/kjijo/Documents/dockerRun/cacert.pem:/etc/ssl/certs/ca-certificates.pem
     depends_on:
       - db_xia_moodle
     networks:
@@ -53,6 +54,7 @@
     command: celery -A openlxp_xia_moodle_project worker -l info --pool=solo
     volumes:
       - ./app:/opt/app/openlxp-xia-moodle
+      - C:/Users/kjijo/Documents/dockerRun/cacert.pem:/etc/ssl/certs/ca-certificates.pem
     environment:
       REQUESTS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'
       AWS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'
@@ -72,6 +74,7 @@
     command: celery -A openlxp_xia_moodle_project beat --scheduler django_celery_beat.schedulers:DatabaseScheduler --loglevel=info --pidfile=/tmp/celerybeat.pid
     volumes:
       - ./app:/opt/app/openlxp-xia-moodle
+      - C:/Users/kjijo/Documents/dockerRun/cacert.pem:/etc/ssl/certs/ca-certificates.pem
     environment:
       REQUESTS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'
       AWS_CA_BUNDLE: '/etc/ssl/certs/ca-certificates.pem'
